{"version":3,"sources":["../../src/activation/relu.js"],"names":["activate","measure","weight","Math","max","delta"],"mappings":";;;;;QAMgBA,Q,GAAAA,Q;QAUAC,O,GAAAA,O;AAhBhB;;;;;;AAMO,SAASD,QAAT,CAAkBE,MAAlB,EAA0B;AAC/B,SAAOC,KAAKC,GAAL,CAAS,CAAT,EAAYF,MAAZ,CAAP;AACD;;AAED;;;;;;AAMO,SAASD,OAAT,CAAiBC,MAAjB,EAAyBG,KAAzB,EAAgC;AACrC,MAAIH,UAAU,CAAd,EAAiB;AACf,WAAO,CAAP;AACD,GAFD,MAEO;AACL,WAAOG,KAAP;AACD;AACF","file":"relu.js","sourcesContent":["/**\n * Relu Activation, aka Rectified Linear Unit Activation\n * @description https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n * @param weight\n * @returns {number}\n */\nexport function activate(weight) {\n  return Math.max(0, weight);\n}\n\n/**\n * Leaky Relu derivative\n * @param weight\n * @param delta\n * @returns {number}\n */\nexport function measure(weight, delta) {\n  if (weight <= 0) {\n    return 0;\n  } else {\n    return delta;\n  }\n}"]}